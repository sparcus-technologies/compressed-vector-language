model_size,model_name,dataset,num_samples,contextual_relevance,answer_completeness,compression_ratio,total_bandwidth_saved_mb,avg_inference_time,total_time,compression_quality
1.1B,TinyLlama/TinyLlama-1.1B-Chat-v1.0,squad,1,0.9297822117805481,1.0,1.0,0.0,18.78540873527527,194.90298128128052,1.0
1.1B,TinyLlama/TinyLlama-1.1B-Chat-v1.0,narrativeqa,1,0.6182628870010376,0.8,1.0,0.0,45.173927307128906,194.90298128128052,1.0
1.5B,Qwen/Qwen2.5-1.5B-Instruct,squad,1,0.8208911418914795,1.0,1.0,0.0,46.109591484069824,248.75047254562378,1.0
1.5B,Qwen/Qwen2.5-1.5B-Instruct,narrativeqa,1,0.6432937383651733,0.4,1.0,0.0,42.054354429244995,248.75047254562378,1.0
